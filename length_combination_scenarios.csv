scenario_id,gpu,model,input_length,output_length,batch_size,use_case
1,L4,LLaMA_3.1_8B,512,512,1,512_512
2,L4,LLaMA_3.1_8B,512,1024,1,512_1024
3,L4,LLaMA_3.1_8B,512,2048,1,512_2048
4,L4,LLaMA_3.1_8B,512,4096,1,512_4096
5,L4,LLaMA_3.1_8B,1024,512,1,1024_512
6,L4,LLaMA_3.1_8B,1024,1024,1,1024_1024
7,L4,LLaMA_3.1_8B,1024,2048,1,1024_2048
8,L4,LLaMA_3.1_8B,1024,4096,1,1024_4096
9,L4,LLaMA_3.1_8B,2048,512,1,2048_512
10,L4,LLaMA_3.1_8B,2048,1024,1,2048_1024
11,L4,LLaMA_3.1_8B,2048,2048,1,2048_2048
12,L4,LLaMA_3.1_8B,2048,4096,1,2048_4096
13,L4,LLaMA_3.1_8B,4096,512,1,4096_512
14,L4,LLaMA_3.1_8B,4096,1024,1,4096_1024
15,L4,LLaMA_3.1_8B,4096,2048,1,4096_2048
16,L4,LLaMA_3.1_8B,4096,4096,1,4096_4096